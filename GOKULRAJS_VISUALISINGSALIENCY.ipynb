{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulraj2004/ExplainableAI/blob/main/GOKULRAJS_VISUALISINGSALIENCY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur2IYlppLmRN"
      },
      "source": [
        "##S.GOKUL RAJ_21BAI1175"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCsTGqWkMeX7"
      },
      "source": [
        "Imports and Using VGG-19 pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1MflElxLK-p",
        "outputId": "ed722d7d-d19b-4ef8-869d-a52fef88130d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:05<00:00, 101MB/s]\n"
          ]
        }
      ],
      "source": [
        "#IMPORTS\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "#Using VGG-19 pretrained model for image classification\n",
        "\n",
        "model = torchvision.models.vgg19(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M0fkjbJrJlZz",
        "outputId": "ae488225-1d6b-43d0-bcef-0516a23b1a26"
      },
      "outputs": [],
      "source": [
        "def download(url,fname):\n",
        "    response = requests.get(url)\n",
        "    with open(fname,\"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "# Downloading the image\n",
        "download(\"https://specials-images.forbesimg.com/imageserve/5db4c7b464b49a0007e9dfac/960x0.jpg?fit=scale\",\"input.jpg\")\n",
        "\n",
        "img1 = Image.open(\"/content/pexels-gareth-davies-1598377.jpg\")\n",
        "img1\n",
        "\n",
        "\n",
        "# Opening the image\n",
        "#img = Image.open('input.jpg')\n",
        "#img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssqYVvBnJqE2"
      },
      "outputs": [],
      "source": [
        "# Preprocess the image\n",
        "def preprocess(image, size=224):\n",
        "    transform = T.Compose([\n",
        "        T.Resize((size,size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        T.Lambda(lambda x: x[None]),\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "'''\n",
        "    Y = (X - μ)/(σ) => Y ~ Distribution(0,1) if X ~ Distribution(μ,σ)\n",
        "    => Y/(1/σ) follows Distribution(0,σ)\n",
        "    => (Y/(1/σ) - (-μ))/1 is actually X and hence follows Distribution(μ,σ)\n",
        "'''\n",
        "def deprocess(image):\n",
        "    transform = T.Compose([\n",
        "        T.Lambda(lambda x: x[0]),\n",
        "        T.Normalize(mean=[0, 0, 0], std=[4.3668, 4.4643, 4.4444]),\n",
        "        T.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
        "        T.ToPILImage(),\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "def show_img(PIL_IMG):\n",
        "    plt.imshow(np.asarray(PIL_IMG))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRhcKgURLBax"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1uUrLT2nJzYT",
        "outputId": "149e8814-5a21-4979-a9c7-f3bc3fda6cf4"
      },
      "outputs": [],
      "source": [
        "# preprocess the image\n",
        "X = preprocess(img)\n",
        "\n",
        "# we would run the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\n",
        "X.requires_grad_()\n",
        "\n",
        "'''\n",
        "forward pass through the model to get the scores, note that VGG-19 model doesn't perform softmax at the end\n",
        "and we also don't need softmax, we need scores, so that's perfect for us.\n",
        "'''\n",
        "\n",
        "scores = model(X)\n",
        "\n",
        "# Get the index corresponding to the maximum score and the maximum score itself.\n",
        "score_max_index = scores.argmax()\n",
        "score_max = scores[0,score_max_index]\n",
        "\n",
        "'''\n",
        "backward function on score_max performs the backward pass in the computation graph and calculates the gradient of\n",
        "score_max with respect to nodes in the computation graph\n",
        "'''\n",
        "score_max.backward()\n",
        "\n",
        "'''\n",
        "Saliency would be the gradient with respect to the input image now. But note that the input image has 3 channels,\n",
        "R, G and B. To derive a single class saliency value for each pixel (i, j),  we take the maximum magnitude\n",
        "across all colour channels.\n",
        "'''\n",
        "saliency, _ = torch.max(X.grad.data.abs(),dim=1)\n",
        "\n",
        "# code to plot the saliency map as a heatmap\n",
        "plt.imshow(saliency[0], cmap=plt.cm.hot)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zq5piwbi9QE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc5VGb4Ka4xd1Rumu/TfFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}